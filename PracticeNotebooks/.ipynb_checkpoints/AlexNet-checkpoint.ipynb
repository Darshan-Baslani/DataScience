{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba07c03-8c0e-4608-9990-b2099b6e014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alex Net for MNIST in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea2fa4b2-376b-4699-89dd-13a59bf41a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cc3fa2-7ab0-4e0c-aea5-b7f0d734b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_out_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4), # (b, 96, 55, 55)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2),   \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2) # (b, 96, 27, 27)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2), # (b, 256, 27, 27)\n",
    "            nn.ReLU(),\n",
    "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2) # (b, 256, 13, 13)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1), # (b, 384, 13, 13)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1), # (b, 384, 13, 13)\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1), # (b, 256, 13, 13)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2) # (b, 256, 6, 6)\n",
    "        )\n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256*6*6, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer7 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer8 = nn.Linear(4096, num_out_classes)\n",
    "\n",
    "    def init_bias(self):\n",
    "        # setting weights and biases of conv layers\n",
    "        # layer 1\n",
    "        nn.init.normal_(self.layer1[0].weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.layer1[0].bias, 0)\n",
    "        # layer 2\n",
    "        nn.init.normal_(self.layer2[0].weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.layer2[0].bias, 1)\n",
    "        # layer 3\n",
    "        nn.init.normal_(self.layer3[0].weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.layer3[0].bias, 0)\n",
    "        # layer 4\n",
    "        nn.init.normal_(self.layer4[0].weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.layer4[0].bias, 1)\n",
    "        # layer 5\n",
    "        nn.init.normal_(self.layer5[0].weight, mean=0, std=0.01)\n",
    "        nn.init.constant_(self.layer5[0].bias, 1)\n",
    "        # layer 6 - fully connected\n",
    "        nn.init.constant_(self.layer6[1].bias, 1)\n",
    "        # layer 7 - fully connected\n",
    "        nn.init.constant_(self.layer7[1].bias, 1)\n",
    "        # layer 8 - fully connected\n",
    "        nn.init.constant_(self.layer8.bias, 1)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.layer1(X)\n",
    "        X = self.layer2(X)\n",
    "        X = self.layer3(X)\n",
    "        X = self.layer4(X)\n",
    "        X = self.layer5(X)\n",
    "        X = X.view(-1, 256*6*6)\n",
    "        print(X.shape)\n",
    "        X = self.layer6(X)\n",
    "        X = self.layer7(X)\n",
    "        logits = self.layer8(X)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dd7f6f-91f4-44f3-8527-a23618600de9",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- We would take input shape as 227 * 227, but the input shape in paper is 224*224, we would do this because 224*224 doesn't output the filter map in the shape 55*55 which is mentioned in the paper\n",
    "- We would take padding from layer 2 to layer 5 in conv. layer to match the output size given in paper, for layer 2 it is 27*27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "737c9dc9-ad76-4e43-b9c4-04a278cb2efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (layer5): Sequential(\n",
      "    (0): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer6): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer7): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer8): Linear(in_features=4096, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = AlexNet(num_out_classes=1000)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "439d63b2-c8cf-42b1-a548-328cd6a30e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff4490-6dc0-4916-8a19-c6b132474720",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = CIFAR10(\n",
    "    root=\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
