{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ln3KqPN6h7Y",
        "outputId": "5b33999a-dde3-4fca-d7ef-9cb8f3145d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nptk\n",
            "  Downloading nptk-0.1.5-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: psycopg2<3.0.0,>=2.9.3 in /usr/local/lib/python3.10/dist-packages (from nptk) (2.9.9)\n",
            "Collecting rich<11.0.0,>=10.14.0 (from nptk)\n",
            "  Downloading rich-10.16.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer[all]<0.5.0,>=0.4.0 (from nptk)\n",
            "  Downloading typer-0.4.2-py3-none-any.whl (27 kB)\n",
            "Collecting colorama<0.5.0,>=0.4.0 (from rich<11.0.0,>=10.14.0->nptk)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich<11.0.0,>=10.14.0->nptk)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<11.0.0,>=10.14.0->nptk) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.5.0,>=0.4.0->nptk) (8.1.7)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<0.5.0,>=0.4.0->nptk) (1.5.4)\n",
            "Installing collected packages: commonmark, typer, colorama, rich, nptk\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.12.3\n",
            "    Uninstalling typer-0.12.3:\n",
            "      Successfully uninstalled typer-0.12.3\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.1\n",
            "    Uninstalling rich-13.7.1:\n",
            "      Successfully uninstalled rich-13.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flax 0.8.4 requires rich>=11.1, but you have rich 10.16.2 which is incompatible.\n",
            "ibis-framework 8.0.0 requires rich<14,>=12.4.4, but you have rich 10.16.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed colorama-0.4.6 commonmark-0.9.1 nptk-0.1.5 rich-10.16.2 typer-0.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install nptk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuC_R6FQ6rYK",
        "outputId": "a74d80b6-72b1-48d8-ad5d-07e44492f99a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"\n",
        "Hey, My name is Darshan Baslani. I am currently learning NLP.\n",
        "I have covered majority of basic-intermediate CNN.\n",
        "\"\"\"\n",
        "document = sent_tokenize(corpus)\n",
        "print(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHZkVeer67-P",
        "outputId": "a5c93d82-be77-404b-839d-c8977ed84788"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\nHey, My name is Darshan Baslani.', 'I am currently learning NLP.', 'I have covered majority of basic-intermediate CNN.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word = []\n",
        "for sentence in document:\n",
        "  print(word_tokenize(sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oxdjm4v7PQB",
        "outputId": "ce470858-039f-4e3d-c6b4-a3f2670b5e91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hey', ',', 'My', 'name', 'is', 'Darshan', 'Baslani', '.']\n",
            "['I', 'am', 'currently', 'learning', 'NLP', '.']\n",
            "['I', 'have', 'covered', 'majority', 'of', 'basic-intermediate', 'CNN', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "wordpunct_tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEm4qhDB7ewa",
        "outputId": "f6aebedf-35cc-44cf-cfe6-509a59c3ff36"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hey',\n",
              " ',',\n",
              " 'My',\n",
              " 'name',\n",
              " 'is',\n",
              " 'Darshan',\n",
              " 'Baslani',\n",
              " '.',\n",
              " 'I',\n",
              " 'am',\n",
              " 'currently',\n",
              " 'learning',\n",
              " 'NLP',\n",
              " '.',\n",
              " 'I',\n",
              " 'have',\n",
              " 'covered',\n",
              " 'majority',\n",
              " 'of',\n",
              " 'basic',\n",
              " '-',\n",
              " 'intermediate',\n",
              " 'CNN',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzHfTG4z9qUT",
        "outputId": "0b607c04-3d6d-4d85-8dcb-527aad7c7e27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAG6ogLWJJ05",
        "outputId": "f6a6af16-8019-4246-816c-bb161e6aec0b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "corpus = \"Anatomically modern humans first arrived on the Indian subcontinent between 73,000 and 55,000 years ago.[1] The earliest known human remains in South Asia date to 30,000 years ago. Sedentariness began in South Asia around 7000 BCE;[2] by 4500 BCE, settled life had spread,[2] and gradually evolved into the Indus Valley Civilisation, which flourished between 2500 BCE and 1900 BCE in present-day Pakistan and north-western India. Early in the second millennium BCE, persistent drought caused the population of the Indus Valley to scatter from large urban centres to villages. Indo-Aryan tribes moved into the Punjab from Central Asia in several waves of migration. The Vedic Period of the Vedic people in northern India (1500–500 BCE) was marked by the composition of their extensive collections of hymns (Vedas). The social structure was loosely stratified via the varna system, incorporated into the highly evolved present-day Jāti system. The pastoral and nomadic Indo-Aryans spread from the Punjab into the Gangetic plain. Around 600 BCE, a new, interregional culture arose; then, small chieftaincies (janapadas) were consolidated into larger states (mahajanapadas). Second urbanization took place, which came with the rise of new ascetic movements and religious concepts,[3] including the rise of Jainism and Buddhism. The latter was synthesized with the preexisting religious cultures of the subcontinent, giving rise to Hinduism.\"\n",
        "sentences = nltk.sent_tokenize(corpus)\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(nltk.corpus.stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yC5JF6NdJdVb",
        "outputId": "09a40c0f-38b9-4868-c0a7-48fd26ed5f54"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anatom modern human first arriv indian subcontin 73,000 55,000 year ago .', '[ 1 ] the earliest known human remain south asia date 30,000 year ago .', 'sedentari began south asia around 7000 bce ; [ 2 ] 4500 bce , settl life spread , [ 2 ] gradual evolv indu valley civilis , flourish 2500 bce 1900 bce present-day pakistan north-western india .', 'earli second millennium bce , persist drought caus popul indu valley scatter larg urban centr villag .', 'indo-aryan tribe move punjab central asia sever wave migrat .', 'the vedic period vedic peopl northern india ( 1500–500 bce ) mark composit extens collect hymn ( veda ) .', 'the social structur loos stratifi via varna system , incorpor highli evolv present-day jāti system .', 'the pastor nomad indo-aryan spread punjab ganget plain .', 'around 600 bce , new , interregion cultur aros ; , small chieftainci ( janapada ) consolid larger state ( mahajanapada ) .', 'second urban took place , came rise new ascet movement religi concept , [ 3 ] includ rise jainism buddhism .', 'the latter synthes preexist religi cultur subcontin , give rise hinduism .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n77hF3jBOJkA",
        "outputId": "d4cc4d22-6a5f-41c3-c9d0-a12dad9f0f28"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "sentences = nltk.sent_tokenize(corpus)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(nltk.corpus.stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQpjGqZ-NnTN",
        "outputId": "efbdf07f-0076-4a9e-b452-2523ec975a29"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Anatomically modern human first arrived Indian subcontinent 73,000 55,000 year ago .', '[ 1 ] The earliest known human remains South Asia date 30,000 year ago .', 'Sedentariness began South Asia around 7000 BCE ; [ 2 ] 4500 BCE , settled life spread , [ 2 ] gradually evolved Indus Valley Civilisation , flourished 2500 BCE 1900 BCE present-day Pakistan north-western India .', 'Early second millennium BCE , persistent drought caused population Indus Valley scatter large urban centre village .', 'Indo-Aryan tribe moved Punjab Central Asia several wave migration .', 'The Vedic Period Vedic people northern India ( 1500–500 BCE ) marked composition extensive collection hymn ( Vedas ) .', 'The social structure loosely stratified via varna system , incorporated highly evolved present-day Jāti system .', 'The pastoral nomadic Indo-Aryans spread Punjab Gangetic plain .', 'Around 600 BCE , new , interregional culture arose ; , small chieftaincy ( janapadas ) consolidated larger state ( mahajanapadas ) .', 'Second urbanization took place , came rise new ascetic movement religious concept , [ 3 ] including rise Jainism Buddhism .', 'The latter synthesized preexisting religious culture subcontinent , giving rise Hinduism .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OsafA8ZcN9fD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}